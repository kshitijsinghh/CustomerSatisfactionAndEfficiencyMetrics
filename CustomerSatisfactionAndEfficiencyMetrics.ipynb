{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CustomerSatisfactionAndEfficiencyMetrics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3OT1WR4vpBE6ihXCl/os/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kshitijsinghh/CustomerSatisfactionAndEfficiencyMetrics/blob/main/CustomerSatisfactionAndEfficiencyMetrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53uYHrJKRw0Z",
        "outputId": "22ca509f-2efd-43da-965b-55b7ee4a17d9"
      },
      "source": [
        "!pip install xlsxwriter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.2-py3-none-any.whl (149 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 149 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GofoOtHdSDtW",
        "outputId": "3b2adefa-2614-4a45-c008-21de88ec6a69"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import xlsxwriter\n",
        "\n",
        "df= pd.read_csv('data.csv')  \n",
        "\n",
        "df['ChatStartTime']= pd.to_datetime(df['ChatStartTime'])  #CONVERTING TIME COLUMNS INTO DATETIME FORMAT\n",
        "df['ChatEndTime']=pd.to_datetime(df['ChatEndTime'])\n",
        "df['is_bus_hr']=0        # HERE I HAVE MADE ANOTHER TABLE THAT MARK WHETHER THE CHATS ARE IN BUSINESS HOURS OR NOT\n",
        "j=0\n",
        "for i in df['ChatStartTime']:\n",
        "   if(i.hour>9 ):\n",
        "     if(i.hour<17 ):\n",
        "\n",
        "      \n",
        "      df.at[j, 'is_bus_hr'] = 1\n",
        "   else:\n",
        "     \n",
        "     \n",
        "\n",
        "     df.at[j, 'is_bus_hr']=0\n",
        "   j=j+1\n",
        "\n",
        "Number_of_Chats_weekly= df.groupby(pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True)).size().reset_index(name = 'Number_of_Chats_weekly') #GROUPED THE DATA ON WEEKLY BASIS AND COUNTED NUMBER OF ROWS AS EACH ROW IS NEW CHAT\n",
        "#print(Number_of_Chats_weekly)\n",
        "\n",
        "Unique_users = df.drop_duplicates(\"UserId\", keep='first')  #CREATED A DATAFRAME OF ALL UNIQUE USERS SO THAT WHEN WE COUNT THE NUMBER OF ROWS AND GROUP THEM ON WEEKLY BASIS \n",
        "Number_of_Unique_Users_weekly= Unique_users.groupby(pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True)).size().reset_index(name = 'Number_of_Unique_Users_weekly')\n",
        "#print(Number_of_Unique_Users_weekly)\n",
        "closed_by_bots= df[(df['ClosedBy']=='System') | (df['ClosedBy']=='Bot') ] #CREATED A DATAFRAME OF ALL THE CHATS CLOSED ONLY BY BOTS AND SYSTEM USNG BOOLEAN MASKING\n",
        "closed_by_bots_weekly= closed_by_bots.groupby(pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True)).size().reset_index(name = 'Closed_by_bots_weekly')  #GROUPED THERE COUNTS ON WEEKLY BASIS\n",
        "#print(closed_by_bots_weekly)\n",
        "Merged1 = pd.merge(Number_of_Chats_weekly,Number_of_Unique_Users_weekly, how='inner', on='ChatStartTime') #MERGING 2 DATAFRAMES A TIME TO MAKE FINAL RESULT DATAFRAME AS ON MERING ALL AT ONCE WAS GIVING RUNTIME PROBLEM\n",
        "Merged2= pd.merge(Merged1,closed_by_bots_weekly, how='inner', on='ChatStartTime') #MERGING DATAFRAMES\n",
        "Agents = (df['ClosedBy']!='Bot') & (df['ClosedBy']!='System')\n",
        "Closed_By_Agents = df[Agents] #CREATED DATAFRAME OF ALL THE CHATS CLOSED BY AGENTS\n",
        "closed_by_Agents_weekly= Closed_By_Agents.groupby(pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True)).size().reset_index(name = 'Closed_by_Agents_weekly') #GROUPED THE CHATS CLOSED BY AGENTS ON WEEKLY BASIS\n",
        "Merged= pd.merge(Merged2,closed_by_Agents_weekly, how='inner', on='ChatStartTime')\n",
        "\n",
        "Merged['Bot_Deflection %']= (Merged['Closed_by_bots_weekly']/Merged['Number_of_Chats_weekly'])*100 #CALCULATED  BOT DEFLECTION % LIKE HOW MANY CHATS WERE CLOSED BY BOS OUT OF TOTAL CHATS\n",
        "Merged.rename(columns={'ChatStartTime':'WeekWiseDates'},inplace=True)\n",
        "Merged['WeekWiseDates']= list(map(lambda x: x.date() , Merged['WeekWiseDates'])) #OUT OF TIMESTAMP TAKING ONLY THE DATES\n",
        "\n",
        "Merged.to_csv(\"ChatMetricsReport.csv\",index=False,na_rep='NULL')  #TILL HERE WE ARE DONE WITH CHAT METRICS SO MAKING A SEPERATE CSV FOR THAT AND IN THE END WILL FINAL XLSX FILE\n",
        "print(Merged.head())\n",
        "\n",
        "\n",
        "\n",
        "# AGENT MTERICS SECTION\n",
        "\n",
        "\n",
        "mask = (df['ClosedBy']!='Bot') & (df['ClosedBy']!='System') \n",
        "Closed_By_Agents = df[mask]\n",
        "Closed_By_Agents.reset_index(inplace=True) #CREATED A DATAFRAME OF CHATS CLOSED BY AGENTS ONLY AND RESET ITS INDEX AS LATER WE'LL DO MULI-INDEXING ON IT\n",
        "\n",
        "Chats_Resolved_By_Each_Agent = Closed_By_Agents.groupby([pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True),'ClosedBy']).size().reset_index(name='Chats_Resolved_By_Each_Agent') #GROUPED HOW MANY CHATS WERE CLOSED BASED ON WEEKS AND AGENTS NAMES\n",
        "#print(Chats_Resolved_By_Each_Agent) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aa= pd.to_timedelta(Closed_By_Agents['AgentFirstResponseTime'])\n",
        "\n",
        "\n",
        "avg_agent_time = list(map(lambda x: x.total_seconds() , aa)) #CONVERTED TOTAL FIRST RESPONSE TIME IN SECONDS FORMAT SO THAT TAKING MEAN WOULD BE EASY\n",
        "\n",
        "\n",
        "ab = pd.Series(avg_agent_time)\n",
        "Closed_By_Agents['AgentFirstResponseTimeInSeconds']=ab \n",
        "#print(Closed_By_Agents['AgentFirstResponseTimeInSeconds'])\n",
        "Avg_First_Response_Time = Closed_By_Agents.groupby([pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True),'ClosedBy']).agg({\"AgentFirstResponseTimeInSeconds\":np.nanmean}).rename(columns={'AgentFirstResponseTimeInSeconds': 'MeanAgentFirstResponseTimeInSeconds'})\n",
        "\n",
        "#print(Avg_First_Response_Time)\n",
        "\n",
        "\n",
        "Closed_By_Agents['Diff']= Closed_By_Agents['ChatEndTime']-Closed_By_Agents['ChatStartTime'] #GOT THE DIFFERENCE BETWEEN START AND END TIME \n",
        "diff_sec = list(map(lambda x: x.total_seconds() , Closed_By_Agents['Diff'])) #CONVERTED THAT DIFFERENCE INTO TOTAL SECONDS SO THAT WE CAN EASILY TAKE MEAN\n",
        "# for i in Closed_By_Agents['Diff']:\n",
        "#   diff_sec.append(i.total_seconds())\n",
        "Closed_By_Agents['Diffsec']= pd.DataFrame(diff_sec)\n",
        "test = Closed_By_Agents[['ChatStartTime','ChatEndTime','Diff','Diffsec']] #BY THIS YOU CAN CHECK WHETHER ABOVE STEPS ARE RIGHT OR NOT\n",
        "\n",
        "Agent_Chat_Resolution_Time = Closed_By_Agents.groupby([pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True),'ClosedBy']).agg({\"Diffsec\":np.nanmean,\"AgentFirstResponseTimeInSeconds\":np.nanmean,\"CsatScore\":np.nanmean}).rename(columns={'Diffsec': 'Agent_Avg_Chat_Resolution_Time','AgentFirstResponseTimeInSeconds':'AgentFirstResponseTimeInSeconds',\"CsatScore\":'MeanCsatScore'})\n",
        "\n",
        "#GROUPED AVERAGE CHAT RESOLUTION TIME GROUPED BY WEEKS AND AGENTS NAME\n",
        "\n",
        "#print(Agent_Chat_Resolution_Time)\n",
        "\n",
        "# merge1= pd.merge(Avg_First_Response_Time,Agent_Chat_Resolution_Time, how='outer', on='ChatStartTime')\n",
        "# print(merge1)\n",
        "Agent_CSAT_Score = Closed_By_Agents.groupby([pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True),'ClosedBy']).agg({\"CsatScore\":np.nanmean}).rename(columns={'CsatScore': 'MeanCsatScore'})\n",
        "\n",
        "#CALCULATED THE MEAN CSAT SCORE GROUPED BY AGENTS NAME AND WEEKS\n",
        "#print(Agent_CSAT_Score)\n",
        "\n",
        "Contacted_in_businesHr = Closed_By_Agents[Closed_By_Agents['is_bus_hr']==1] #CREATED THE DATAFRAME OF ALL THE CHATS IN BUSINESS HOURS\n",
        "Agent_CSAT_Score_in_BHr = Contacted_in_businesHr.groupby([pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True),'ClosedBy']).agg({\"CsatScore\":np.nanmean}).rename(columns={'CsatScore': 'MeanCsatScoreInBusinessHr'})\n",
        "#OUT OF DATAFRAME CREATED GROUPED THE MEAN CSAT SCORE BY AGENTS NAME AND WEEKS\n",
        "\n",
        "#print(Agent_CSAT_Score_in_BHr)\n",
        "NotContacted_in_businesHr = Closed_By_Agents[Closed_By_Agents['is_bus_hr']==0]\n",
        "Agent_CSAT_Score_not_in_BHr = NotContacted_in_businesHr.groupby([pd.Grouper(key='ChatStartTime', axis=0, \n",
        "                      freq='1W', sort=True),'ClosedBy']).agg({\"CsatScore\":np.nanmean}).rename(columns={'CsatScore':'MeanCsatScoreNotInBHr'})\n",
        "\n",
        "#SIMILARLY CREATED THE DATAFRAME OF ALL THE CHATS IN NON BUSINESS HOURS AND GROUPED THE MEAN CSAT SCORE IN THAT TIME FRAME BY AGENTS NAME AND WEEKS\n",
        "merged1 =  pd.merge(Agent_CSAT_Score_not_in_BHr,Agent_CSAT_Score_in_BHr, how='outer', on=['ChatStartTime','ClosedBy'])\n",
        "#print(merged1)\n",
        "merged2 = pd.merge(merged1,Agent_Chat_Resolution_Time, how='outer', on=['ChatStartTime','ClosedBy'])\n",
        "\n",
        "# print(merged2)\n",
        "merged_final = pd.merge(merged2,Chats_Resolved_By_Each_Agent, how='outer', on=['ChatStartTime','ClosedBy'])\n",
        "merged_final.rename(columns={'ChatStartTime':'WeekWiseDates'},inplace=True)\n",
        "merged_final['WeekWiseDates']= list(map(lambda x: x.date() , merged_final['WeekWiseDates']))\n",
        "merged_final.to_csv(\"AgentMetricsReport.csv\",index=True) #AGENT METRICS PART IS COMPLETE , SO CREATED ITS SEPERATE CSV AS WELL\n",
        "print(merged_final.head())\n",
        "\n",
        "\n",
        "#BONUS METRICS SECTION\n",
        "\n",
        "mask = (df['ClosedBy']!='Bot') & (df['ClosedBy']!='System') \n",
        "df = df[mask]\n",
        "\n",
        "df['AgentAssignmentTimestamp']=pd.to_datetime(df['AgentAssignmentTimestamp'], errors='coerce') #CONVERTED AgentAssignmentTimestamp IN DATE TIME FORMAT\n",
        "df['CumulativeTime']=df['ChatEndTime']-df['ChatStartTime'] # CUMULATIVE TME\n",
        "df['ActiveTime']=df['ChatEndTime']-df['AgentAssignmentTimestamp'] #ACTIVE TIME\n",
        "ActiveTimeInSec = list(map(lambda x: x.total_seconds() , df['ActiveTime'])) #CONVETED IT TO TOTAL SECOND AS IT WOULD BE EASY TO CALCULATE MEAN\n",
        "df['ActiveTimeInSec']= ActiveTimeInSec\n",
        "df[['ActiveTime','ActiveTimeInSec']]\n",
        "CumulativeTimeInSec = list(map(lambda x: x.total_seconds() , df['CumulativeTime'])) #CONVETED IT TO TOTAL SECOND AS IT WOULD BE EASY TO CALCULATE MEAN\n",
        "df['CumulativeTimeInSec']= CumulativeTimeInSec\n",
        "Bonus_Metrics = df.groupby('ClosedBy').agg({'CumulativeTimeInSec':np.nanmean,'ActiveTimeInSec':np.nanmean}).rename(columns={'CumulativeTimeInSec': 'MeanCumulativeTimeInSec','ActiveTimeInSec':'MeanActiveTimeInSec'})\n",
        "# GROUPED THE MEAN CUMULATIVE TIME AND ACTIVE TIME BY AGENTS NAME\n",
        "print(Bonus_Metrics.head())\n",
        "\n",
        "\n",
        "writer = pd.ExcelWriter('Report.xlsx', engine='xlsxwriter')\n",
        "\n",
        "#store your dataframes in a  dict, where the key is the sheet name you want\n",
        "frames = {'AGENT_MERICS': merged_final, 'CHAT_METRICS': Merged, 'BONUS_METRCS':Bonus_Metrics }\n",
        "\n",
        "#now loop thru and put each on a specific sheet\n",
        "for sheet, frame in  frames.items(): # .use .items for python 3.X\n",
        "    frame.to_excel(writer, sheet_name = sheet)\n",
        "\n",
        "#critical last step\n",
        "writer.save()\n",
        "#HERE YOU'LL GET XLSX REPORT ALL THREE TABS IN ON SHEET\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  WeekWiseDates  ...  Bot_Deflection %\n",
            "0    2021-01-03  ...         65.326633\n",
            "1    2021-01-10  ...               NaN\n",
            "2    2021-01-17  ...               NaN\n",
            "3    2021-01-24  ...               NaN\n",
            "4    2021-01-31  ...        100.000000\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  WeekWiseDates  ClosedBy  ...  MeanCsatScore  Chats_Resolved_By_Each_Agent\n",
            "0    2021-01-03      Adaa  ...       0.833333                             6\n",
            "1    2021-01-03     Akash  ...       1.666667                             3\n",
            "2    2021-01-03    Anisha  ...       3.333333                             3\n",
            "3    2021-01-03     Azaan  ...       0.000000                             4\n",
            "4    2021-01-03  Dalphine  ...       1.000000                             4\n",
            "\n",
            "[5 rows x 8 columns]\n",
            "          MeanCumulativeTimeInSec  MeanActiveTimeInSec\n",
            "ClosedBy                                              \n",
            "Abbas                  853.315789           727.578947\n",
            "Adaa                  1356.685714          1249.557143\n",
            "Adil                  1019.125000           792.093750\n",
            "Ajay                   910.240741           777.888889\n",
            "Akash                  600.440000           472.360000\n"
          ]
        }
      ]
    }
  ]
}